{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def add_layer(inputs,in_size,out_size,n_layer,activation_function=None): #activation_function=None线性函数\n",
    "    layer_name=\"layer%s\" % n_layer\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            Weights = tf.Variable(tf.random_normal([in_size,out_size])) #Weight中都是随机变量\n",
    "            tf.summary.histogram(layer_name+\"/weights\",Weights) #可视化观看变量\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1,out_size])+0.1) #biases推荐初始值不为0\n",
    "            tf.summary.histogram(layer_name+\"/biases\",biases) #可视化观看变量\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.matmul(inputs,Weights)+biases #inputs*Weight+biases\n",
    "            tf.summary.histogram(layer_name+\"/Wx_plus_b\",Wx_plus_b) #可视化观看变量    \n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b)\n",
    "        tf.summary.histogram(layer_name+\"/outputs\",outputs) #可视化观看变量    \n",
    "        return outputs\n",
    "    \n",
    "#创建数据x_data，y_data    \n",
    "x_data = np.linspace(-1,1,300)[:,np.newaxis] #[-1,1]区间，300个单位，np.newaxis增加维度    \n",
    "noise = np.random.normal(0,0.05,x_data.shape) #噪点    \n",
    "y_data = np.square(x_data)-0.5+noise\n",
    "    \n",
    "with tf.name_scope('inputs'): #结构化\n",
    "    xs = tf.placeholder(tf.float32,[None,1],name='x_input')    \n",
    "    ys = tf.placeholder(tf.float32,[None,1],name='y_input')\n",
    "    \n",
    "#三层神经，输入层（1个神经元），隐藏层（10神经元），输出层（1个神经元）    \n",
    "l1 = add_layer(xs,1,10,n_layer=1,activation_function=tf.nn.relu) #隐藏层    \n",
    "prediction = add_layer(l1,10,1,n_layer=2,activation_function=None) #输出层    \n",
    "    \n",
    "#predition值与y_data差别    \n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction),reduction_indices=[1])) #square()平方,sum()求和,mean()平均值    \n",
    "    tf.summary.scalar('loss',loss) #可视化观看常量    \n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(loss) #0.1学习效率,minimize(loss)减小loss误差    \n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "#合并到Summary中    \n",
    "merged = tf.summary.merge_all()\n",
    "#选定可视化存储目录    \n",
    "writer = tf.summary.FileWriter(\"Desktop/\",sess.graph)    \n",
    "sess.run(init) #先执行init    \n",
    "    \n",
    "#训练1k次    \n",
    "for i in range(1000):\n",
    "    sess.run(train_step,feed_dict={xs:x_data,ys:y_data})    \n",
    "    if i%50==0:\n",
    "        result = sess.run(merged,feed_dict={xs:x_data,ys:y_data}) #merged也是需要run的    \n",
    "        writer.add_summary(result,i) #result是summary类型的，需要放入writer中，i步数（x轴）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
